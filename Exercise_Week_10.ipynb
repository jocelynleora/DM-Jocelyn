{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JuFb1MP_O5EW",
    "outputId": "17a158d8-8df8-4af8-d8cb-b15b95e590c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlxtend\n",
      "  Downloading mlxtend-0.23.0-py3-none-any.whl (1.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4 MB 1.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16.2 in /Users/jocelynleora_/opt/anaconda3/lib/python3.9/site-packages (from mlxtend) (1.21.5)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /Users/jocelynleora_/opt/anaconda3/lib/python3.9/site-packages (from mlxtend) (1.0.2)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /Users/jocelynleora_/opt/anaconda3/lib/python3.9/site-packages (from mlxtend) (1.4.2)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in /Users/jocelynleora_/opt/anaconda3/lib/python3.9/site-packages (from mlxtend) (3.5.1)\n",
      "Requirement already satisfied: joblib>=0.13.2 in /Users/jocelynleora_/opt/anaconda3/lib/python3.9/site-packages (from mlxtend) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.2.1 in /Users/jocelynleora_/opt/anaconda3/lib/python3.9/site-packages (from mlxtend) (1.7.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/jocelynleora_/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.0->mlxtend) (3.0.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/jocelynleora_/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/jocelynleora_/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.0->mlxtend) (4.25.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/jocelynleora_/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.0->mlxtend) (9.0.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/jocelynleora_/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.0->mlxtend) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/jocelynleora_/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jocelynleora_/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.0->mlxtend) (21.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jocelynleora_/opt/anaconda3/lib/python3.9/site-packages (from pandas>=0.24.2->mlxtend) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jocelynleora_/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/jocelynleora_/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=1.0.2->mlxtend) (2.2.0)\n",
      "Installing collected packages: mlxtend\n",
      "Successfully installed mlxtend-0.23.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "! pip install mlxtend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wDYkmRlZPSXY"
   },
   "source": [
    "# Association Rule for Store Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IYfOAa9fPjln"
   },
   "source": [
    "In this case study, we will explore how association rule can be used to analyze the items that are usualy purcased together.\n",
    "\n",
    "you can refer to this article to find out about apriori and association rule:\n",
    "https://rasbt.github.io/mlxtend/user_guide/frequent_patterns/apriori/\n",
    "https://rasbt.github.io/mlxtend/user_guide/frequent_patterns/association_rules/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7EOg6BIYPxt4"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gp0OZCjrQT1n"
   },
   "source": [
    "We will use the dataset of the transaction in a certain store. You can get the dataset here: \n",
    "https://gist.githubusercontent.com/Harsh-Git-Hub/2979ec48043928ad9033d8469928e751/raw/72de943e040b8bd0d087624b154d41b2ba9d9b60/retail_dataset.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "LDF65VBRQjFL",
    "outputId": "e9c6b17c-3450-4b26-af48-e963cc0dd11b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First five transactions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bread</td>\n",
       "      <td>Wine</td>\n",
       "      <td>Eggs</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Cheese</td>\n",
       "      <td>Pencil</td>\n",
       "      <td>Diaper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bread</td>\n",
       "      <td>Cheese</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Diaper</td>\n",
       "      <td>Wine</td>\n",
       "      <td>Milk</td>\n",
       "      <td>Pencil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cheese</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Eggs</td>\n",
       "      <td>Milk</td>\n",
       "      <td>Wine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cheese</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Eggs</td>\n",
       "      <td>Milk</td>\n",
       "      <td>Wine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meat</td>\n",
       "      <td>Pencil</td>\n",
       "      <td>Wine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1     2       3       4       5       6\n",
       "0   Bread    Wine  Eggs    Meat  Cheese  Pencil  Diaper\n",
       "1   Bread  Cheese  Meat  Diaper    Wine    Milk  Pencil\n",
       "2  Cheese    Meat  Eggs    Milk    Wine     NaN     NaN\n",
       "3  Cheese    Meat  Eggs    Milk    Wine     NaN     NaN\n",
       "4    Meat  Pencil  Wine     NaN     NaN     NaN     NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data set and show the first five transaction\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://gist.githubusercontent.com/Harsh-Git-Hub/2979ec48043928ad9033d8469928e751/raw/72de943e040b8bd0d087624b154d41b2ba9d9b60/retail_dataset.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Show the first five transactions\n",
    "print(\"First five transactions:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IkfhUabDQup9"
   },
   "source": [
    "# Get the set of product that has been purchased\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the unique product that has been purchased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Awz6VzuMwR_-",
    "outputId": "1fc181b3-cffe-48fe-9d3b-066323061907"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique products that have been purchased:\n",
      "['Bread' 'Wine' 'Eggs' 'Meat' 'Cheese' 'Pencil' 'Diaper' 'Milk' 'Bagel']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "purchased_products_set = set(df.values.flatten())\n",
    "\n",
    "unique_products = df.stack().dropna().unique()\n",
    "\n",
    "print(\"\\nUnique products that have been purchased:\")\n",
    "print(unique_products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4g4k83bP07H"
   },
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEnL1bXtRLXe"
   },
   "source": [
    "In this step, we will transform our dataset so that we will have a one hot encoding based on the purchased products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "N4wdVmFWQ_yg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoded DataFrame:\n",
      "     Bagel  Bread  Cheese  Diaper  Eggs  Meat  Milk  Pencil  Wine\n",
      "0        0      1       1       1     1     1     0       1     1\n",
      "1        0      1       1       1     0     1     1       1     1\n",
      "2        0      0       1       0     1     1     1       0     1\n",
      "3        0      0       1       0     1     1     1       0     1\n",
      "4        0      0       0       0     0     1     0       1     1\n",
      "..     ...    ...     ...     ...   ...   ...   ...     ...   ...\n",
      "310      0      1       1       0     1     0     0       0     0\n",
      "311      0      0       0       0     0     1     1       1     0\n",
      "312      0      1       1       1     1     1     0       1     1\n",
      "313      0      0       1       0     0     1     0       0     0\n",
      "314      1      1       0       0     1     1     0       0     1\n",
      "\n",
      "[315 rows x 9 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tw/y5qcj89571q4xpmr5sfyv96c0000gn/T/ipykernel_1791/3935992399.py:5: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.sum(level=1) should use df.groupby(level=1).sum().\n",
      "  encoded_df = pd.get_dummies(itemset.apply(pd.Series).stack()).sum(level=0)\n"
     ]
    }
   ],
   "source": [
    "#create an itemset based on the products\n",
    "itemset = df.apply(lambda row: list(row.dropna()), axis=1)\n",
    "\n",
    "# encoding the feature\n",
    "encoded_df = pd.get_dummies(itemset.apply(pd.Series).stack()).sum(level=0)\n",
    "\n",
    "print(\"\\nEncoded DataFrame:\")\n",
    "print(encoded_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "v67eBdxByEJX",
    "outputId": "b05c05fb-7ae1-4fbe-a01a-d6985c360f5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New DataFrame with Encoded Features:\n",
      "          0       1       2       3       4       5       6  Bagel  Bread  \\\n",
      "0     Bread    Wine    Eggs    Meat  Cheese  Pencil  Diaper      0      1   \n",
      "1     Bread  Cheese    Meat  Diaper    Wine    Milk  Pencil      0      1   \n",
      "2    Cheese    Meat    Eggs    Milk    Wine     NaN     NaN      0      0   \n",
      "3    Cheese    Meat    Eggs    Milk    Wine     NaN     NaN      0      0   \n",
      "4      Meat  Pencil    Wine     NaN     NaN     NaN     NaN      0      0   \n",
      "..      ...     ...     ...     ...     ...     ...     ...    ...    ...   \n",
      "310   Bread    Eggs  Cheese     NaN     NaN     NaN     NaN      0      1   \n",
      "311    Meat    Milk  Pencil     NaN     NaN     NaN     NaN      0      0   \n",
      "312   Bread  Cheese    Eggs    Meat  Pencil  Diaper    Wine      0      1   \n",
      "313    Meat  Cheese     NaN     NaN     NaN     NaN     NaN      0      0   \n",
      "314    Eggs    Wine   Bagel   Bread    Meat     NaN     NaN      1      1   \n",
      "\n",
      "     Cheese  Diaper  Eggs  Meat  Milk  Pencil  Wine  \n",
      "0         1       1     1     1     0       1     1  \n",
      "1         1       1     0     1     1       1     1  \n",
      "2         1       0     1     1     1       0     1  \n",
      "3         1       0     1     1     1       0     1  \n",
      "4         0       0     0     1     0       1     1  \n",
      "..      ...     ...   ...   ...   ...     ...   ...  \n",
      "310       1       0     1     0     0       0     0  \n",
      "311       0       0     0     1     1       1     0  \n",
      "312       1       1     1     1     0       1     1  \n",
      "313       1       0     0     1     0       0     0  \n",
      "314       0       0     1     1     0       0     1  \n",
      "\n",
      "[315 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "  # create new dataframe from the encoded features\n",
    "new_df = pd.concat([df, encoded_df], axis=1)\n",
    "\n",
    "    \n",
    "  # show the new dataframe\n",
    "print(\"\\nNew DataFrame with Encoded Features:\")\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBJmzWAAS4Mw"
   },
   "source": [
    "Since, the encoded dataframe consist of the empty column. We will drop the NaN column or select all columns other than the first column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "2eHZu15xyTqm",
    "outputId": "7bffff16-fc02-48fe-bc98-7616bf75908e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned DataFrame:\n",
      "          1       2       3       4       5       6  Bagel  Bread  Cheese  \\\n",
      "0      Wine    Eggs    Meat  Cheese  Pencil  Diaper      0      1       1   \n",
      "1    Cheese    Meat  Diaper    Wine    Milk  Pencil      0      1       1   \n",
      "2      Meat    Eggs    Milk    Wine     NaN     NaN      0      0       1   \n",
      "3      Meat    Eggs    Milk    Wine     NaN     NaN      0      0       1   \n",
      "4    Pencil    Wine     NaN     NaN     NaN     NaN      0      0       0   \n",
      "..      ...     ...     ...     ...     ...     ...    ...    ...     ...   \n",
      "310    Eggs  Cheese     NaN     NaN     NaN     NaN      0      1       1   \n",
      "311    Milk  Pencil     NaN     NaN     NaN     NaN      0      0       0   \n",
      "312  Cheese    Eggs    Meat  Pencil  Diaper    Wine      0      1       1   \n",
      "313  Cheese     NaN     NaN     NaN     NaN     NaN      0      0       1   \n",
      "314    Wine   Bagel   Bread    Meat     NaN     NaN      1      1       0   \n",
      "\n",
      "     Diaper  Eggs  Meat  Milk  Pencil  Wine  \n",
      "0         1     1     1     0       1     1  \n",
      "1         1     0     1     1       1     1  \n",
      "2         0     1     1     1       0     1  \n",
      "3         0     1     1     1       0     1  \n",
      "4         0     0     1     0       1     1  \n",
      "..      ...   ...   ...   ...     ...   ...  \n",
      "310       0     1     0     0       0     0  \n",
      "311       0     0     1     1       1     0  \n",
      "312       1     1     1     0       1     1  \n",
      "313       0     0     1     0       0     0  \n",
      "314       0     1     1     0       0     1  \n",
      "\n",
      "[315 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "# Drop the NaN column or select all columns other than the first column\n",
    "new_df_cleaned = new_df.iloc[:, 1:].dropna(axis=1, how='all')\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(\"\\nCleaned DataFrame:\")\n",
    "print(new_df_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_UXDzSNPP35P"
   },
   "source": [
    "## Apriori Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-jD3ea4TYMV"
   },
   "source": [
    "We will use appriori algorithm to determine the frequently purchased products. \n",
    "For this case study, we will min_support=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "BLA4Jqhoyjof",
    "outputId": "bc435206-1be2-41e6-b05b-0f1ba125e955"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     support              itemsets\n",
      "0   0.425397               (Bagel)\n",
      "1   0.504762               (Bread)\n",
      "2   0.501587              (Cheese)\n",
      "3   0.406349              (Diaper)\n",
      "4   0.438095                (Eggs)\n",
      "5   0.476190                (Meat)\n",
      "6   0.501587                (Milk)\n",
      "7   0.361905              (Pencil)\n",
      "8   0.438095                (Wine)\n",
      "9   0.279365        (Bread, Bagel)\n",
      "10  0.225397         (Milk, Bagel)\n",
      "11  0.238095       (Bread, Cheese)\n",
      "12  0.231746       (Bread, Diaper)\n",
      "13  0.206349         (Bread, Meat)\n",
      "14  0.279365         (Milk, Bread)\n",
      "15  0.200000       (Pencil, Bread)\n",
      "16  0.244444         (Wine, Bread)\n",
      "17  0.200000      (Cheese, Diaper)\n",
      "18  0.298413        (Eggs, Cheese)\n",
      "19  0.323810        (Meat, Cheese)\n",
      "20  0.304762        (Milk, Cheese)\n",
      "21  0.200000      (Pencil, Cheese)\n",
      "22  0.269841        (Wine, Cheese)\n",
      "23  0.234921        (Wine, Diaper)\n",
      "24  0.266667          (Eggs, Meat)\n",
      "25  0.244444          (Eggs, Milk)\n",
      "26  0.241270          (Eggs, Wine)\n",
      "27  0.244444          (Milk, Meat)\n",
      "28  0.250794          (Wine, Meat)\n",
      "29  0.219048          (Milk, Wine)\n",
      "30  0.200000        (Pencil, Wine)\n",
      "31  0.215873  (Eggs, Meat, Cheese)\n",
      "32  0.203175  (Milk, Meat, Cheese)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jocelynleora_/opt/anaconda3/lib/python3.9/site-packages/mlxtend/frequent_patterns/fpcommon.py:110: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "min_support = 0.2\n",
    "frequent_itemsets_apriori = apriori(encoded_df, min_support=min_support, use_colnames=True)\n",
    "\n",
    "print(frequent_itemsets_apriori)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uEr2YXHrVOIA"
   },
   "source": [
    "Then, we will generate association rule of the frequent itemset based on confidence level with the threshold=0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "id": "5GalSXOoy6H8",
    "outputId": "2fc5a421-bca1-41c8-f96a-e24f49280d99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Association Rules:\n",
      "       antecedents consequents  antecedent support  consequent support  \\\n",
      "0          (Bagel)     (Bread)            0.425397            0.504762   \n",
      "1           (Eggs)    (Cheese)            0.438095            0.501587   \n",
      "2           (Meat)    (Cheese)            0.476190            0.501587   \n",
      "3         (Cheese)      (Meat)            0.501587            0.476190   \n",
      "4           (Milk)    (Cheese)            0.501587            0.501587   \n",
      "5         (Cheese)      (Milk)            0.501587            0.501587   \n",
      "6           (Wine)    (Cheese)            0.438095            0.501587   \n",
      "7           (Eggs)      (Meat)            0.438095            0.476190   \n",
      "8     (Eggs, Meat)    (Cheese)            0.266667            0.501587   \n",
      "9   (Eggs, Cheese)      (Meat)            0.298413            0.476190   \n",
      "10  (Meat, Cheese)      (Eggs)            0.323810            0.438095   \n",
      "11    (Milk, Meat)    (Cheese)            0.244444            0.501587   \n",
      "12  (Milk, Cheese)      (Meat)            0.304762            0.476190   \n",
      "13  (Meat, Cheese)      (Milk)            0.323810            0.501587   \n",
      "\n",
      "     support  confidence      lift  leverage  conviction  zhangs_metric  \n",
      "0   0.279365    0.656716  1.301042  0.064641    1.442650       0.402687  \n",
      "1   0.298413    0.681159  1.358008  0.078670    1.563203       0.469167  \n",
      "2   0.323810    0.680000  1.355696  0.084958    1.557540       0.500891  \n",
      "3   0.323810    0.645570  1.355696  0.084958    1.477891       0.526414  \n",
      "4   0.304762    0.607595  1.211344  0.053172    1.270148       0.350053  \n",
      "5   0.304762    0.607595  1.211344  0.053172    1.270148       0.350053  \n",
      "6   0.269841    0.615942  1.227986  0.050098    1.297754       0.330409  \n",
      "7   0.266667    0.608696  1.278261  0.058050    1.338624       0.387409  \n",
      "8   0.215873    0.809524  1.613924  0.082116    2.616667       0.518717  \n",
      "9   0.215873    0.723404  1.519149  0.073772    1.893773       0.487091  \n",
      "10  0.215873    0.666667  1.521739  0.074014    1.685714       0.507042  \n",
      "11  0.203175    0.831169  1.657077  0.080564    2.952137       0.524816  \n",
      "12  0.203175    0.666667  1.400000  0.058050    1.571429       0.410959  \n",
      "13  0.203175    0.627451  1.250931  0.040756    1.337845       0.296655  \n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "# Set the confidence threshold\n",
    "min_confidence = 0.6\n",
    "\n",
    "# Generate association rules\n",
    "rules = association_rules(frequent_itemsets_apriori, metric=\"confidence\", min_threshold=min_confidence)\n",
    "\n",
    "# Display the association rules\n",
    "print(\"Association Rules:\")\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide explanation about __antecedent support__, __consequent support__, __support__, __confidence__, __lift__, __leverage__ and __conviction__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- Antecedent Support:\n",
    "Shows how often the first item (on the left) appears alone.\n",
    "\n",
    "- Consequent Support:\n",
    "Shows how often the second item (on the right) appears alone.\n",
    "\n",
    "- Support:\n",
    "Tells us how often both items appear together.\n",
    "\n",
    "- Confidence:\n",
    "Tells us how likely the second item is to be bought when the first item is bought.\n",
    "\n",
    "- Lift:\n",
    "Tells us how much more likely the second item is bought when the first item is bought, compared to when the second item is bought independently.\n",
    "\n",
    "- Leverage:\n",
    "Measures the difference between how often the two items are bought together and how often we would expect them to be bought together by chance.\n",
    "\n",
    "- Conviction:\n",
    "Measures how much more likely the second item is to be bought independently, compared to when it's bought with the first item."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
